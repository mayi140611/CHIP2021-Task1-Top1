{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "815a1c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../checkpoint/medbert2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89a9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at trueto/medbert-base-chinese were not used when initializing Bert: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing Bert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Bert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Bert were not initialized from the model checkpoint at trueto/medbert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight', 'relative_pos_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  3%|█▏                                     | 99/3111 [03:25<1:47:27,  2.14s/it][99/3111],train loss is:1.012112\n",
      "  6%|██▍                                   | 199/3111 [06:58<1:43:24,  2.13s/it][199/3111],train loss is:0.889344\n",
      " 10%|███▋                                  | 299/3111 [10:31<1:40:44,  2.15s/it][299/3111],train loss is:0.822572\n",
      " 13%|████▊                                 | 399/3111 [14:07<1:37:59,  2.17s/it][399/3111],train loss is:0.780319\n",
      " 16%|██████                                | 499/3111 [17:44<1:35:08,  2.19s/it][499/3111],train loss is:0.747589\n",
      " 19%|███████▎                              | 599/3111 [21:23<1:31:44,  2.19s/it][599/3111],train loss is:0.726422\n",
      " 22%|████████▌                             | 699/3111 [25:04<1:28:53,  2.21s/it][699/3111],train loss is:0.707527\n",
      " 26%|█████████▊                            | 799/3111 [28:45<1:25:22,  2.22s/it][799/3111],train loss is:0.692839\n",
      " 29%|██████████▉                           | 899/3111 [32:27<1:22:17,  2.23s/it][899/3111],train loss is:0.681554\n",
      " 32%|████████████▏                         | 999/3111 [36:11<1:19:00,  2.24s/it][999/3111],train loss is:0.672872\n",
      " 35%|█████████████                        | 1099/3111 [39:56<1:15:08,  2.24s/it][1099/3111],train loss is:0.662628\n",
      " 39%|██████████████▎                      | 1199/3111 [43:40<1:11:30,  2.24s/it][1199/3111],train loss is:0.656115\n",
      " 42%|███████████████▍                     | 1299/3111 [47:24<1:07:50,  2.25s/it][1299/3111],train loss is:0.649812\n",
      " 45%|████████████████▋                    | 1399/3111 [51:09<1:03:59,  2.24s/it][1399/3111],train loss is:0.643998\n",
      " 48%|█████████████████▊                   | 1499/3111 [54:53<1:00:25,  2.25s/it][1499/3111],train loss is:0.639115\n",
      " 51%|████████████████████                   | 1599/3111 [58:37<56:20,  2.24s/it][1599/3111],train loss is:0.633871\n",
      " 55%|████████████████████▏                | 1699/3111 [1:02:21<52:39,  2.24s/it][1699/3111],train loss is:0.629566\n",
      " 58%|█████████████████████▍               | 1799/3111 [1:06:05<48:45,  2.23s/it][1799/3111],train loss is:0.625156\n",
      " 61%|██████████████████████▌              | 1899/3111 [1:09:49<45:18,  2.24s/it][1899/3111],train loss is:0.621370\n",
      " 64%|███████████████████████▊             | 1999/3111 [1:13:33<41:32,  2.24s/it][1999/3111],train loss is:0.617690\n",
      " 67%|████████████████████████▉            | 2099/3111 [1:17:17<37:50,  2.24s/it][2099/3111],train loss is:0.614274\n",
      " 71%|██████████████████████████▏          | 2199/3111 [1:21:01<34:00,  2.24s/it][2199/3111],train loss is:0.611167\n",
      " 74%|███████████████████████████▎         | 2299/3111 [1:24:46<30:18,  2.24s/it][2299/3111],train loss is:0.608726\n",
      " 77%|████████████████████████████▌        | 2399/3111 [1:28:30<26:31,  2.23s/it][2399/3111],train loss is:0.606350\n",
      " 80%|█████████████████████████████▋       | 2499/3111 [1:32:14<22:49,  2.24s/it][2499/3111],train loss is:0.603929\n",
      " 84%|██████████████████████████████▉      | 2599/3111 [1:35:58<19:07,  2.24s/it][2599/3111],train loss is:0.601145\n",
      " 87%|████████████████████████████████     | 2699/3111 [1:39:42<15:24,  2.24s/it][2699/3111],train loss is:0.598744\n",
      " 90%|█████████████████████████████████▎   | 2799/3111 [1:43:26<11:34,  2.23s/it][2799/3111],train loss is:0.596560\n",
      " 93%|██████████████████████████████████▍  | 2899/3111 [1:47:11<07:56,  2.25s/it][2899/3111],train loss is:0.594371\n",
      " 96%|███████████████████████████████████▋ | 2999/3111 [1:50:54<04:10,  2.24s/it][2999/3111],train loss is:0.592286\n",
      "100%|████████████████████████████████████▊| 3099/3111 [1:54:38<00:26,  2.24s/it][3099/3111],train loss is:0.590331\n",
      "100%|█████████████████████████████████████| 3111/3111 [1:55:04<00:00,  2.22s/it]\n",
      "epoch:[0],train loss is:0.590320 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         不标注       0.89      0.84      0.87      2102\n",
      "          其他       0.75      0.76      0.75       467\n",
      "          阳性       0.95      0.96      0.95      7219\n",
      "          阴性       0.90      0.90      0.90      1271\n",
      "\n",
      "    accuracy                           0.92     11059\n",
      "   macro avg       0.87      0.87      0.87     11059\n",
      "weighted avg       0.92      0.92      0.92     11059\n",
      "\n",
      "confusion_matrix_: \n",
      " [[1771   34  256   41]\n",
      " [  12  354   67   34]\n",
      " [ 177   51 6939   52]\n",
      " [  22   34   65 1150]]\n",
      "test loss is:0.481657,test acc is:0.923592,f1_score is:0.869306\n",
      "  3%|█▏                                     | 99/3111 [03:41<1:52:39,  2.24s/it][99/3111],train loss is:0.492788\n",
      "  6%|██▍                                   | 199/3111 [07:25<1:48:53,  2.24s/it][199/3111],train loss is:0.495144\n",
      " 10%|███▋                                  | 299/3111 [11:09<1:45:06,  2.24s/it][299/3111],train loss is:0.490378\n",
      " 13%|████▊                                 | 399/3111 [14:53<1:41:21,  2.24s/it][399/3111],train loss is:0.493653\n",
      " 16%|██████                                | 499/3111 [18:37<1:37:22,  2.24s/it][499/3111],train loss is:0.492569\n",
      " 19%|███████▎                              | 599/3111 [22:21<1:33:47,  2.24s/it][599/3111],train loss is:0.490402\n",
      " 22%|████████▌                             | 699/3111 [26:05<1:29:43,  2.23s/it][699/3111],train loss is:0.489479\n",
      " 26%|█████████▊                            | 799/3111 [29:49<1:26:21,  2.24s/it][799/3111],train loss is:0.488395\n",
      " 29%|██████████▉                           | 899/3111 [33:33<1:22:23,  2.23s/it][899/3111],train loss is:0.486948\n",
      " 32%|████████████▏                         | 999/3111 [37:17<1:18:39,  2.23s/it][999/3111],train loss is:0.486474\n",
      " 35%|█████████████                        | 1099/3111 [41:01<1:14:58,  2.24s/it][1099/3111],train loss is:0.486214\n",
      " 39%|██████████████▎                      | 1199/3111 [44:45<1:11:08,  2.23s/it][1199/3111],train loss is:0.486691\n",
      " 42%|███████████████▍                     | 1299/3111 [48:29<1:07:40,  2.24s/it][1299/3111],train loss is:0.486443\n",
      " 45%|████████████████▋                    | 1399/3111 [52:13<1:03:54,  2.24s/it][1399/3111],train loss is:0.486207\n",
      " 48%|█████████████████▊                   | 1499/3111 [55:57<1:00:04,  2.24s/it][1499/3111],train loss is:0.485210\n",
      " 51%|████████████████████                   | 1599/3111 [59:42<56:21,  2.24s/it][1599/3111],train loss is:0.485173\n",
      " 55%|████████████████████▏                | 1699/3111 [1:03:26<52:42,  2.24s/it][1699/3111],train loss is:0.486238\n",
      " 58%|█████████████████████▍               | 1799/3111 [1:07:11<49:03,  2.24s/it][1799/3111],train loss is:0.486637\n",
      " 61%|██████████████████████▌              | 1899/3111 [1:10:56<45:29,  2.25s/it][1899/3111],train loss is:0.486882\n",
      " 64%|███████████████████████▊             | 1999/3111 [1:14:41<41:49,  2.26s/it][1999/3111],train loss is:0.486453\n",
      " 67%|████████████████████████▉            | 2099/3111 [1:18:26<37:48,  2.24s/it][2099/3111],train loss is:0.486364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████▏          | 2199/3111 [1:22:10<34:05,  2.24s/it][2199/3111],train loss is:0.486278\n",
      " 74%|███████████████████████████▎         | 2299/3111 [1:25:55<30:18,  2.24s/it][2299/3111],train loss is:0.486268\n",
      " 77%|████████████████████████████▌        | 2399/3111 [1:29:39<26:34,  2.24s/it][2399/3111],train loss is:0.486492\n",
      " 80%|█████████████████████████████▋       | 2499/3111 [1:33:24<22:50,  2.24s/it][2499/3111],train loss is:0.486218\n",
      " 84%|██████████████████████████████▉      | 2599/3111 [1:37:08<19:02,  2.23s/it][2599/3111],train loss is:0.486271\n",
      " 87%|████████████████████████████████     | 2699/3111 [1:40:51<15:23,  2.24s/it][2699/3111],train loss is:0.485869\n",
      " 90%|█████████████████████████████████▎   | 2799/3111 [1:44:36<11:40,  2.24s/it][2799/3111],train loss is:0.485649\n",
      " 93%|██████████████████████████████████▍  | 2899/3111 [1:48:20<07:55,  2.24s/it][2899/3111],train loss is:0.485413\n",
      " 96%|███████████████████████████████████▋ | 2999/3111 [1:52:05<04:10,  2.24s/it][2999/3111],train loss is:0.485196\n",
      "100%|████████████████████████████████████▊| 3099/3111 [1:55:49<00:26,  2.24s/it][3099/3111],train loss is:0.485196\n",
      "100%|█████████████████████████████████████| 3111/3111 [1:56:14<00:00,  2.24s/it]\n",
      "epoch:[1],train loss is:0.485277 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         不标注       0.91      0.88      0.90      2102\n",
      "          其他       0.77      0.83      0.80       467\n",
      "          阳性       0.96      0.97      0.96      7219\n",
      "          阴性       0.93      0.91      0.92      1271\n",
      "\n",
      "    accuracy                           0.94     11059\n",
      "   macro avg       0.89      0.90      0.89     11059\n",
      "weighted avg       0.94      0.94      0.94     11059\n",
      "\n",
      "confusion_matrix_: \n",
      " [[1855   32  185   30]\n",
      " [  12  386   50   19]\n",
      " [ 142   49 6983   45]\n",
      " [  22   34   55 1160]]\n",
      "test loss is:0.457135,test acc is:0.938964,f1_score is:0.894422\n",
      "Some weights of the model checkpoint at trueto/medbert-base-chinese were not used when initializing Bert: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing Bert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Bert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Bert were not initialized from the model checkpoint at trueto/medbert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight', 'relative_pos_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  3%|█▏                                     | 99/3111 [03:41<1:53:09,  2.25s/it][99/3111],train loss is:1.010532\n",
      "  6%|██▍                                   | 199/3111 [07:26<1:48:02,  2.23s/it][199/3111],train loss is:0.885819\n",
      " 10%|███▋                                  | 299/3111 [11:07<1:44:11,  2.22s/it][299/3111],train loss is:0.822020\n",
      " 13%|████▊                                 | 399/3111 [14:50<1:41:02,  2.24s/it][399/3111],train loss is:0.775564\n",
      " 16%|██████                                | 499/3111 [18:34<1:37:13,  2.23s/it][499/3111],train loss is:0.744641\n",
      " 19%|███████▎                              | 599/3111 [22:17<1:33:42,  2.24s/it][599/3111],train loss is:0.721391\n",
      " 22%|████████▌                             | 699/3111 [26:00<1:30:01,  2.24s/it][699/3111],train loss is:0.706063\n",
      " 26%|█████████▊                            | 799/3111 [29:43<1:26:10,  2.24s/it][799/3111],train loss is:0.692499\n",
      " 29%|██████████▉                           | 899/3111 [33:27<1:22:03,  2.23s/it][899/3111],train loss is:0.679726\n",
      " 32%|████████████▏                         | 999/3111 [37:10<1:18:26,  2.23s/it][999/3111],train loss is:0.669920\n",
      " 35%|█████████████                        | 1099/3111 [40:54<1:14:51,  2.23s/it][1099/3111],train loss is:0.661886\n",
      " 39%|██████████████▎                      | 1199/3111 [44:37<1:10:53,  2.22s/it][1199/3111],train loss is:0.655145\n",
      " 42%|███████████████▍                     | 1299/3111 [48:20<1:07:22,  2.23s/it][1299/3111],train loss is:0.648051\n",
      " 45%|████████████████▋                    | 1399/3111 [52:03<1:03:45,  2.23s/it][1399/3111],train loss is:0.642601\n",
      " 48%|██████████████████▊                    | 1499/3111 [55:47<59:54,  2.23s/it][1499/3111],train loss is:0.636938\n",
      " 51%|████████████████████                   | 1599/3111 [59:30<55:58,  2.22s/it][1599/3111],train loss is:0.632118\n",
      " 55%|████████████████████▏                | 1699/3111 [1:03:13<52:34,  2.23s/it][1699/3111],train loss is:0.627311\n",
      " 58%|█████████████████████▍               | 1799/3111 [1:06:57<48:46,  2.23s/it][1799/3111],train loss is:0.623783\n",
      " 61%|██████████████████████▌              | 1899/3111 [1:10:40<45:13,  2.24s/it][1899/3111],train loss is:0.620706\n",
      " 64%|███████████████████████▊             | 1999/3111 [1:14:23<41:29,  2.24s/it][1999/3111],train loss is:0.616594\n",
      " 67%|████████████████████████▉            | 2099/3111 [1:18:07<37:41,  2.23s/it][2099/3111],train loss is:0.613395\n",
      " 71%|██████████████████████████▏          | 2199/3111 [1:21:51<34:08,  2.25s/it][2199/3111],train loss is:0.610611\n",
      " 74%|███████████████████████████▎         | 2299/3111 [1:25:34<30:11,  2.23s/it][2299/3111],train loss is:0.607818\n",
      " 77%|████████████████████████████▌        | 2399/3111 [1:29:18<26:30,  2.23s/it][2399/3111],train loss is:0.605122\n",
      " 80%|█████████████████████████████▋       | 2499/3111 [1:33:02<22:50,  2.24s/it][2499/3111],train loss is:0.603103\n",
      " 84%|██████████████████████████████▉      | 2599/3111 [1:36:45<19:04,  2.23s/it][2599/3111],train loss is:0.600629\n",
      " 87%|████████████████████████████████     | 2699/3111 [1:40:29<15:19,  2.23s/it][2699/3111],train loss is:0.598388\n",
      " 90%|█████████████████████████████████▎   | 2799/3111 [1:44:13<11:39,  2.24s/it][2799/3111],train loss is:0.596330\n",
      " 93%|██████████████████████████████████▍  | 2899/3111 [1:47:56<07:54,  2.24s/it][2899/3111],train loss is:0.594412\n",
      " 96%|███████████████████████████████████▋ | 2999/3111 [1:51:40<04:10,  2.24s/it][2999/3111],train loss is:0.592612\n",
      "100%|████████████████████████████████████▊| 3099/3111 [1:55:23<00:26,  2.24s/it][3099/3111],train loss is:0.590623\n",
      "100%|█████████████████████████████████████| 3111/3111 [1:55:48<00:00,  2.23s/it]\n",
      "epoch:[0],train loss is:0.590339 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         不标注       0.89      0.86      0.87      2121\n",
      "          其他       0.77      0.75      0.76       451\n",
      "          阳性       0.95      0.96      0.96      7229\n",
      "          阴性       0.92      0.91      0.92      1258\n",
      "\n",
      "    accuracy                           0.93     11059\n",
      "   macro avg       0.88      0.87      0.88     11059\n",
      "weighted avg       0.93      0.93      0.93     11059\n",
      "\n",
      "confusion_matrix_: \n",
      " [[1820   16  244   41]\n",
      " [  28  339   62   22]\n",
      " [ 180   51 6963   35]\n",
      " [  20   33   57 1148]]\n",
      "test loss is:0.477546,test acc is:0.928655,f1_score is:0.877157\n",
      "  3%|█▏                                     | 99/3111 [03:41<1:52:24,  2.24s/it][99/3111],train loss is:0.489660\n",
      "  6%|██▍                                   | 199/3111 [07:25<1:48:37,  2.24s/it][199/3111],train loss is:0.492445\n",
      " 10%|███▋                                  | 299/3111 [11:08<1:44:56,  2.24s/it][299/3111],train loss is:0.491293\n",
      " 13%|████▊                                 | 399/3111 [14:52<1:41:16,  2.24s/it][399/3111],train loss is:0.489899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|██████                                | 499/3111 [18:36<1:37:33,  2.24s/it][499/3111],train loss is:0.489555\n",
      " 19%|███████▎                              | 599/3111 [22:20<1:33:38,  2.24s/it][599/3111],train loss is:0.490274\n",
      " 22%|████████▌                             | 699/3111 [26:04<1:30:00,  2.24s/it][699/3111],train loss is:0.491220\n",
      " 26%|█████████▊                            | 799/3111 [29:48<1:26:24,  2.24s/it][799/3111],train loss is:0.491286\n",
      " 29%|██████████▉                           | 899/3111 [33:32<1:22:46,  2.25s/it][899/3111],train loss is:0.491132\n",
      " 32%|████████████▏                         | 999/3111 [37:16<1:18:34,  2.23s/it][999/3111],train loss is:0.489598\n",
      " 35%|█████████████                        | 1099/3111 [41:00<1:15:06,  2.24s/it][1099/3111],train loss is:0.489164\n",
      " 39%|██████████████▎                      | 1199/3111 [44:44<1:11:27,  2.24s/it][1199/3111],train loss is:0.489190\n",
      " 42%|███████████████▍                     | 1299/3111 [48:28<1:07:48,  2.25s/it][1299/3111],train loss is:0.488801\n",
      " 45%|████████████████▋                    | 1399/3111 [52:11<1:03:30,  2.23s/it][1399/3111],train loss is:0.488315\n",
      " 48%|█████████████████▊                   | 1499/3111 [55:55<1:00:03,  2.24s/it][1499/3111],train loss is:0.488109\n",
      " 51%|████████████████████                   | 1599/3111 [59:38<56:11,  2.23s/it][1599/3111],train loss is:0.487958\n",
      " 55%|████████████████████▏                | 1699/3111 [1:03:22<52:37,  2.24s/it][1699/3111],train loss is:0.487553\n",
      " 58%|█████████████████████▍               | 1799/3111 [1:07:05<48:58,  2.24s/it][1799/3111],train loss is:0.487450\n",
      " 61%|██████████████████████▌              | 1899/3111 [1:10:49<45:13,  2.24s/it][1899/3111],train loss is:0.487395\n",
      " 64%|███████████████████████▊             | 1999/3111 [1:14:32<41:24,  2.23s/it][1999/3111],train loss is:0.487621\n",
      " 67%|████████████████████████▉            | 2099/3111 [1:18:16<37:44,  2.24s/it][2099/3111],train loss is:0.487156\n",
      " 71%|██████████████████████████▏          | 2199/3111 [1:21:59<33:55,  2.23s/it][2199/3111],train loss is:0.487217\n",
      " 74%|███████████████████████████▎         | 2299/3111 [1:25:43<30:13,  2.23s/it][2299/3111],train loss is:0.487158\n",
      " 77%|████████████████████████████▌        | 2399/3111 [1:29:26<26:36,  2.24s/it][2399/3111],train loss is:0.486652\n",
      " 80%|█████████████████████████████▋       | 2499/3111 [1:33:10<22:43,  2.23s/it][2499/3111],train loss is:0.486915\n",
      " 84%|██████████████████████████████▉      | 2599/3111 [1:36:53<19:06,  2.24s/it][2599/3111],train loss is:0.486808\n",
      " 87%|████████████████████████████████     | 2699/3111 [1:40:37<15:17,  2.23s/it][2699/3111],train loss is:0.486719\n",
      " 90%|█████████████████████████████████▎   | 2799/3111 [1:44:20<11:36,  2.23s/it][2799/3111],train loss is:0.486629\n",
      " 93%|██████████████████████████████████▍  | 2899/3111 [1:48:03<07:53,  2.24s/it][2899/3111],train loss is:0.486623\n",
      " 96%|███████████████████████████████████▋ | 2999/3111 [1:51:47<04:10,  2.24s/it][2999/3111],train loss is:0.486254\n",
      "100%|████████████████████████████████████▊| 3099/3111 [1:55:30<00:26,  2.24s/it][3099/3111],train loss is:0.486120\n",
      "100%|█████████████████████████████████████| 3111/3111 [1:55:56<00:00,  2.24s/it]\n",
      "epoch:[1],train loss is:0.486201 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         不标注       0.91      0.89      0.90      2121\n",
      "          其他       0.86      0.76      0.81       451\n",
      "          阳性       0.96      0.97      0.96      7229\n",
      "          阴性       0.92      0.94      0.93      1258\n",
      "\n",
      "    accuracy                           0.94     11059\n",
      "   macro avg       0.91      0.89      0.90     11059\n",
      "weighted avg       0.94      0.94      0.94     11059\n",
      "\n",
      "confusion_matrix_: \n",
      " [[1888    9  190   34]\n",
      " [  21  345   65   20]\n",
      " [ 149   34 7003   43]\n",
      " [  19   15   46 1178]]\n",
      "test loss is:0.455013,test acc is:0.941676,f1_score is:0.900325\n",
      "Some weights of the model checkpoint at trueto/medbert-base-chinese were not used when initializing Bert: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing Bert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Bert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Bert were not initialized from the model checkpoint at trueto/medbert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight', 'relative_pos_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  3%|█▏                                     | 99/3111 [03:40<1:51:51,  2.23s/it][99/3111],train loss is:0.988323\n",
      "  6%|██▍                                   | 199/3111 [07:23<1:48:19,  2.23s/it][199/3111],train loss is:0.884761\n",
      " 10%|███▋                                  | 299/3111 [11:06<1:44:48,  2.24s/it][299/3111],train loss is:0.820411\n",
      " 13%|████▊                                 | 399/3111 [14:49<1:40:35,  2.23s/it][399/3111],train loss is:0.778476\n",
      " 16%|██████                                | 499/3111 [18:33<1:37:18,  2.24s/it][499/3111],train loss is:0.747574\n",
      " 19%|███████▎                              | 599/3111 [22:16<1:33:30,  2.23s/it][599/3111],train loss is:0.722692\n",
      " 22%|████████▌                             | 699/3111 [25:59<1:30:05,  2.24s/it][699/3111],train loss is:0.705656\n",
      " 26%|█████████▊                            | 799/3111 [29:43<1:26:24,  2.24s/it][799/3111],train loss is:0.691905\n",
      " 29%|██████████▉                           | 899/3111 [33:27<1:22:20,  2.23s/it][899/3111],train loss is:0.681305\n",
      " 32%|████████████▏                         | 999/3111 [37:10<1:18:27,  2.23s/it][999/3111],train loss is:0.671059\n",
      " 35%|█████████████                        | 1099/3111 [40:54<1:14:49,  2.23s/it][1099/3111],train loss is:0.663700\n",
      " 39%|██████████████▎                      | 1199/3111 [44:37<1:11:14,  2.24s/it][1199/3111],train loss is:0.657186\n",
      " 42%|███████████████▍                     | 1299/3111 [48:21<1:07:31,  2.24s/it][1299/3111],train loss is:0.650722\n",
      " 45%|████████████████▋                    | 1399/3111 [52:04<1:03:55,  2.24s/it][1399/3111],train loss is:0.645249\n",
      " 48%|█████████████████▊                   | 1499/3111 [55:48<1:00:10,  2.24s/it][1499/3111],train loss is:0.639659\n",
      " 51%|████████████████████                   | 1599/3111 [59:31<56:11,  2.23s/it][1599/3111],train loss is:0.634716\n",
      " 55%|████████████████████▏                | 1699/3111 [1:03:14<52:33,  2.23s/it][1699/3111],train loss is:0.630562\n",
      " 58%|█████████████████████▍               | 1799/3111 [1:06:58<48:59,  2.24s/it][1799/3111],train loss is:0.626343\n",
      " 61%|██████████████████████▌              | 1899/3111 [1:10:41<45:07,  2.23s/it][1899/3111],train loss is:0.622498\n",
      " 64%|███████████████████████▊             | 1999/3111 [1:14:25<41:20,  2.23s/it][1999/3111],train loss is:0.618312\n",
      " 67%|████████████████████████▉            | 2099/3111 [1:18:08<37:50,  2.24s/it][2099/3111],train loss is:0.615615\n",
      " 71%|██████████████████████████▏          | 2199/3111 [1:21:52<33:54,  2.23s/it][2199/3111],train loss is:0.613419\n",
      " 74%|███████████████████████████▎         | 2299/3111 [1:25:35<30:19,  2.24s/it][2299/3111],train loss is:0.610130\n",
      " 77%|████████████████████████████▌        | 2399/3111 [1:29:19<26:28,  2.23s/it][2399/3111],train loss is:0.606696\n",
      " 80%|█████████████████████████████▋       | 2499/3111 [1:33:02<22:48,  2.24s/it][2499/3111],train loss is:0.604780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████▉      | 2599/3111 [1:36:45<19:06,  2.24s/it][2599/3111],train loss is:0.602791\n",
      " 87%|████████████████████████████████     | 2699/3111 [1:40:29<15:19,  2.23s/it][2699/3111],train loss is:0.600457\n",
      " 90%|█████████████████████████████████▎   | 2799/3111 [1:44:12<11:37,  2.24s/it][2799/3111],train loss is:0.598326\n",
      " 93%|██████████████████████████████████▍  | 2899/3111 [1:47:55<07:52,  2.23s/it][2899/3111],train loss is:0.595727\n",
      " 96%|███████████████████████████████████▋ | 2999/3111 [1:51:38<04:09,  2.23s/it][2999/3111],train loss is:0.593747\n",
      "100%|████████████████████████████████████▊| 3099/3111 [1:55:21<00:26,  2.23s/it][3099/3111],train loss is:0.591224\n",
      "100%|█████████████████████████████████████| 3111/3111 [1:55:47<00:00,  2.23s/it]\n",
      "epoch:[0],train loss is:0.590895 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         不标注       0.89      0.85      0.87      2086\n",
      "          其他       0.77      0.71      0.74       495\n",
      "          阳性       0.94      0.96      0.95      7162\n",
      "          阴性       0.90      0.90      0.90      1316\n",
      "\n",
      "    accuracy                           0.92     11059\n",
      "   macro avg       0.88      0.86      0.87     11059\n",
      "weighted avg       0.92      0.92      0.92     11059\n",
      "\n",
      "confusion_matrix_: \n",
      " [[1774   23  261   28]\n",
      " [  23  353   83   36]\n",
      " [ 168   45 6886   63]\n",
      " [  29   39   62 1186]]\n",
      "test loss is:0.484643,test acc is:0.922235,f1_score is:0.865984\n",
      "  3%|█▏                                     | 99/3111 [03:40<1:51:38,  2.22s/it][99/3111],train loss is:0.504558\n",
      "  6%|██▍                                   | 199/3111 [07:24<1:48:39,  2.24s/it][199/3111],train loss is:0.498911\n",
      " 10%|███▋                                  | 299/3111 [11:07<1:45:00,  2.24s/it][299/3111],train loss is:0.496963\n",
      " 13%|████▊                                 | 399/3111 [14:50<1:41:10,  2.24s/it][399/3111],train loss is:0.494103\n",
      " 16%|██████                                | 499/3111 [18:34<1:37:19,  2.24s/it][499/3111],train loss is:0.493251\n",
      " 19%|███████▎                              | 599/3111 [22:17<1:33:26,  2.23s/it][599/3111],train loss is:0.491388\n",
      " 22%|████████▌                             | 699/3111 [26:01<1:29:35,  2.23s/it][699/3111],train loss is:0.490178\n",
      " 26%|█████████▊                            | 799/3111 [29:44<1:25:57,  2.23s/it][799/3111],train loss is:0.490368\n",
      " 29%|██████████▉                           | 899/3111 [33:27<1:22:02,  2.23s/it][899/3111],train loss is:0.489805\n",
      " 32%|████████████▏                         | 999/3111 [37:11<1:18:18,  2.22s/it][999/3111],train loss is:0.489486\n",
      " 35%|█████████████                        | 1099/3111 [40:54<1:15:04,  2.24s/it][1099/3111],train loss is:0.488293\n",
      " 39%|██████████████▎                      | 1199/3111 [44:38<1:11:33,  2.25s/it][1199/3111],train loss is:0.487962\n",
      " 42%|███████████████▍                     | 1299/3111 [48:22<1:07:22,  2.23s/it][1299/3111],train loss is:0.488170\n",
      " 45%|████████████████▋                    | 1399/3111 [52:05<1:03:53,  2.24s/it][1399/3111],train loss is:0.487860\n",
      " 48%|██████████████████▊                    | 1499/3111 [55:49<59:57,  2.23s/it][1499/3111],train loss is:0.488040\n",
      " 51%|████████████████████                   | 1599/3111 [59:33<56:28,  2.24s/it][1599/3111],train loss is:0.487814\n",
      " 55%|████████████████████▏                | 1699/3111 [1:03:16<52:33,  2.23s/it][1699/3111],train loss is:0.488182\n",
      " 58%|█████████████████████▍               | 1799/3111 [1:07:00<48:40,  2.23s/it][1799/3111],train loss is:0.488060\n",
      " 61%|██████████████████████▌              | 1899/3111 [1:10:43<45:00,  2.23s/it][1899/3111],train loss is:0.487704\n",
      " 64%|███████████████████████▊             | 1999/3111 [1:14:26<41:24,  2.23s/it][1999/3111],train loss is:0.487558\n",
      " 67%|████████████████████████▉            | 2099/3111 [1:18:09<37:41,  2.23s/it][2099/3111],train loss is:0.487104\n",
      " 71%|██████████████████████████▏          | 2199/3111 [1:21:52<34:01,  2.24s/it][2199/3111],train loss is:0.486731\n",
      " 74%|███████████████████████████▎         | 2299/3111 [1:25:36<30:15,  2.24s/it][2299/3111],train loss is:0.486880\n",
      " 77%|████████████████████████████▌        | 2399/3111 [1:29:19<26:29,  2.23s/it][2399/3111],train loss is:0.486877\n",
      " 80%|█████████████████████████████▋       | 2499/3111 [1:33:02<22:49,  2.24s/it][2499/3111],train loss is:0.486541\n",
      " 84%|██████████████████████████████▉      | 2599/3111 [1:36:46<19:07,  2.24s/it][2599/3111],train loss is:0.486159\n",
      " 87%|████████████████████████████████     | 2699/3111 [1:40:29<15:20,  2.23s/it][2699/3111],train loss is:0.486064\n",
      " 90%|█████████████████████████████████▎   | 2799/3111 [1:44:12<11:36,  2.23s/it][2799/3111],train loss is:0.486129\n",
      " 93%|██████████████████████████████████▍  | 2899/3111 [1:47:55<07:54,  2.24s/it][2899/3111],train loss is:0.486021\n",
      " 96%|███████████████████████████████████▋ | 2999/3111 [1:51:38<04:09,  2.23s/it][2999/3111],train loss is:0.485777\n",
      "100%|████████████████████████████████████▊| 3099/3111 [1:55:22<00:26,  2.23s/it][3099/3111],train loss is:0.485498\n",
      "100%|█████████████████████████████████████| 3111/3111 [1:55:47<00:00,  2.23s/it]\n",
      "epoch:[1],train loss is:0.485528 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         不标注       0.90      0.88      0.89      2086\n",
      "          其他       0.80      0.77      0.79       495\n",
      "          阳性       0.96      0.97      0.96      7162\n",
      "          阴性       0.92      0.92      0.92      1316\n",
      "\n",
      "    accuracy                           0.94     11059\n",
      "   macro avg       0.90      0.89      0.89     11059\n",
      "weighted avg       0.94      0.94      0.94     11059\n",
      "\n",
      "confusion_matrix_: \n",
      " [[1845   24  194   23]\n",
      " [  23  383   56   33]\n",
      " [ 156   43 6917   46]\n",
      " [  24   27   51 1214]]\n",
      "test loss is:0.464660,test acc is:0.936703,f1_score is:0.891297\n",
      "Some weights of the model checkpoint at trueto/medbert-base-chinese were not used when initializing Bert: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing Bert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Bert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Bert were not initialized from the model checkpoint at trueto/medbert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight', 'relative_pos_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  3%|█▏                                     | 99/3111 [03:41<1:53:02,  2.25s/it][99/3111],train loss is:0.988552\n",
      "  6%|██▍                                   | 199/3111 [07:24<1:47:15,  2.21s/it][199/3111],train loss is:0.879325\n",
      " 10%|███▋                                  | 299/3111 [11:06<1:44:38,  2.23s/it][299/3111],train loss is:0.816778\n",
      " 13%|████▊                                 | 399/3111 [14:49<1:40:46,  2.23s/it][399/3111],train loss is:0.777045\n",
      " 16%|██████                                | 499/3111 [18:32<1:37:21,  2.24s/it][499/3111],train loss is:0.749657\n",
      " 19%|███████▎                              | 599/3111 [22:15<1:33:15,  2.23s/it][599/3111],train loss is:0.728639\n",
      " 22%|████████▌                             | 699/3111 [25:58<1:29:44,  2.23s/it][699/3111],train loss is:0.709926\n",
      " 26%|█████████▊                            | 799/3111 [29:41<1:25:41,  2.22s/it][799/3111],train loss is:0.694525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29%|██████████▉                           | 899/3111 [33:24<1:22:27,  2.24s/it][899/3111],train loss is:0.683146\n",
      " 32%|████████████▏                         | 999/3111 [37:07<1:18:27,  2.23s/it][999/3111],train loss is:0.673309\n",
      " 35%|█████████████                        | 1099/3111 [40:51<1:14:53,  2.23s/it][1099/3111],train loss is:0.664946\n",
      " 39%|██████████████▎                      | 1199/3111 [44:34<1:10:50,  2.22s/it][1199/3111],train loss is:0.656736\n",
      " 42%|███████████████▍                     | 1299/3111 [48:17<1:07:17,  2.23s/it][1299/3111],train loss is:0.650027\n",
      " 45%|████████████████▋                    | 1399/3111 [52:00<1:03:45,  2.23s/it][1399/3111],train loss is:0.643731\n",
      " 48%|██████████████████▊                    | 1499/3111 [55:43<59:52,  2.23s/it][1499/3111],train loss is:0.638701\n",
      " 51%|████████████████████                   | 1599/3111 [59:26<56:09,  2.23s/it][1599/3111],train loss is:0.633702\n",
      " 55%|████████████████████▏                | 1699/3111 [1:03:09<52:36,  2.24s/it][1699/3111],train loss is:0.629340\n",
      " 58%|█████████████████████▍               | 1799/3111 [1:06:52<48:49,  2.23s/it][1799/3111],train loss is:0.625728\n",
      " 61%|██████████████████████▌              | 1899/3111 [1:10:35<44:59,  2.23s/it][1899/3111],train loss is:0.622004\n",
      " 64%|███████████████████████▊             | 1999/3111 [1:14:18<41:17,  2.23s/it][1999/3111],train loss is:0.618958\n",
      " 67%|████████████████████████▉            | 2099/3111 [1:18:01<37:36,  2.23s/it][2099/3111],train loss is:0.616244\n",
      " 71%|██████████████████████████▏          | 2199/3111 [1:21:44<33:53,  2.23s/it][2199/3111],train loss is:0.612385\n",
      " 74%|███████████████████████████▎         | 2299/3111 [1:25:27<30:10,  2.23s/it][2299/3111],train loss is:0.609550\n",
      " 77%|████████████████████████████▌        | 2399/3111 [1:29:10<26:26,  2.23s/it][2399/3111],train loss is:0.607139\n",
      " 80%|█████████████████████████████▋       | 2499/3111 [1:32:53<22:46,  2.23s/it][2499/3111],train loss is:0.604530\n",
      " 84%|██████████████████████████████▉      | 2599/3111 [1:36:36<18:57,  2.22s/it][2599/3111],train loss is:0.602287\n",
      " 87%|████████████████████████████████     | 2699/3111 [1:40:20<15:18,  2.23s/it][2699/3111],train loss is:0.600244\n",
      " 90%|█████████████████████████████████▎   | 2799/3111 [1:44:03<11:35,  2.23s/it][2799/3111],train loss is:0.598449\n",
      " 93%|██████████████████████████████████▍  | 2899/3111 [1:47:46<07:53,  2.23s/it][2899/3111],train loss is:0.596304\n",
      " 96%|███████████████████████████████████▋ | 2999/3111 [1:51:29<04:11,  2.24s/it][2999/3111],train loss is:0.594631\n",
      "100%|████████████████████████████████████▊| 3099/3111 [1:55:12<00:26,  2.23s/it][3099/3111],train loss is:0.592721\n",
      "100%|█████████████████████████████████████| 3111/3111 [1:55:37<00:00,  2.23s/it]\n",
      "epoch:[0],train loss is:0.592558 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         不标注       0.90      0.85      0.88      2109\n",
      "          其他       0.81      0.70      0.75       486\n",
      "          阳性       0.95      0.97      0.96      7192\n",
      "          阴性       0.89      0.94      0.91      1272\n",
      "\n",
      "    accuracy                           0.93     11059\n",
      "   macro avg       0.89      0.86      0.87     11059\n",
      "weighted avg       0.93      0.93      0.93     11059\n",
      "\n",
      "confusion_matrix_: \n",
      " [[1802   24  238   45]\n",
      " [  19  338   81   48]\n",
      " [ 160   36 6943   53]\n",
      " [  20   20   42 1190]]\n",
      "test loss is:0.477063,test acc is:0.928927,f1_score is:0.873792\n",
      "  3%|█▏                                     | 99/3111 [03:40<1:51:45,  2.23s/it][99/3111],train loss is:0.489847\n",
      "  6%|██▍                                   | 199/3111 [07:24<1:48:13,  2.23s/it][199/3111],train loss is:0.489905\n",
      " 10%|███▋                                  | 299/3111 [11:06<1:44:37,  2.23s/it][299/3111],train loss is:0.488763\n",
      " 13%|████▊                                 | 399/3111 [14:49<1:40:49,  2.23s/it][399/3111],train loss is:0.490096\n",
      " 16%|██████                                | 499/3111 [18:33<1:37:05,  2.23s/it][499/3111],train loss is:0.488534\n",
      " 19%|███████▎                              | 599/3111 [22:16<1:33:31,  2.23s/it][599/3111],train loss is:0.488585\n",
      " 22%|████████▌                             | 699/3111 [25:59<1:29:44,  2.23s/it][699/3111],train loss is:0.488311\n",
      " 26%|█████████▊                            | 799/3111 [29:42<1:26:11,  2.24s/it][799/3111],train loss is:0.489217\n",
      " 29%|██████████▉                           | 899/3111 [33:25<1:22:11,  2.23s/it][899/3111],train loss is:0.488761\n",
      " 32%|████████████▏                         | 999/3111 [37:08<1:18:51,  2.24s/it][999/3111],train loss is:0.488415\n",
      " 35%|█████████████                        | 1099/3111 [40:52<1:14:50,  2.23s/it][1099/3111],train loss is:0.487549\n",
      " 39%|██████████████▎                      | 1199/3111 [44:35<1:11:22,  2.24s/it][1199/3111],train loss is:0.486910\n",
      " 42%|███████████████▍                     | 1299/3111 [48:19<1:07:35,  2.24s/it][1299/3111],train loss is:0.487395\n",
      " 45%|████████████████▋                    | 1399/3111 [52:03<1:04:05,  2.25s/it][1399/3111],train loss is:0.487205\n",
      " 48%|██████████████████▊                    | 1499/3111 [55:46<59:53,  2.23s/it][1499/3111],train loss is:0.487807\n",
      " 51%|████████████████████                   | 1599/3111 [59:30<56:38,  2.25s/it][1599/3111],train loss is:0.487761\n",
      " 55%|████████████████████▏                | 1699/3111 [1:03:14<52:53,  2.25s/it][1699/3111],train loss is:0.488176\n",
      " 58%|█████████████████████▍               | 1799/3111 [1:06:57<48:44,  2.23s/it][1799/3111],train loss is:0.488436\n",
      " 61%|██████████████████████▌              | 1899/3111 [1:10:41<45:08,  2.23s/it][1899/3111],train loss is:0.488161\n",
      " 64%|███████████████████████▊             | 1999/3111 [1:14:24<41:24,  2.23s/it][1999/3111],train loss is:0.487992\n",
      " 67%|████████████████████████▉            | 2099/3111 [1:18:08<37:37,  2.23s/it][2099/3111],train loss is:0.487440\n",
      " 71%|██████████████████████████▏          | 2199/3111 [1:21:52<33:59,  2.24s/it][2199/3111],train loss is:0.487227\n",
      " 74%|███████████████████████████▎         | 2299/3111 [1:25:35<30:15,  2.24s/it][2299/3111],train loss is:0.487186\n",
      " 77%|████████████████████████████▌        | 2399/3111 [1:29:19<26:35,  2.24s/it][2399/3111],train loss is:0.487187\n",
      " 80%|█████████████████████████████▋       | 2499/3111 [1:33:02<22:53,  2.24s/it][2499/3111],train loss is:0.486962\n",
      " 84%|██████████████████████████████▉      | 2599/3111 [1:36:45<19:02,  2.23s/it][2599/3111],train loss is:0.486601\n",
      " 87%|████████████████████████████████     | 2699/3111 [1:40:29<15:20,  2.23s/it][2699/3111],train loss is:0.486474\n",
      " 90%|█████████████████████████████████▎   | 2799/3111 [1:44:12<11:35,  2.23s/it][2799/3111],train loss is:0.486475\n",
      " 93%|██████████████████████████████████▍  | 2899/3111 [1:47:56<07:54,  2.24s/it][2899/3111],train loss is:0.486088\n",
      " 96%|███████████████████████████████████▋ | 2999/3111 [1:51:39<04:10,  2.23s/it][2999/3111],train loss is:0.485944\n",
      "100%|████████████████████████████████████▊| 3099/3111 [1:55:22<00:26,  2.23s/it][3099/3111],train loss is:0.485723\n",
      "100%|█████████████████████████████████████| 3111/3111 [1:55:48<00:00,  2.23s/it]\n",
      "epoch:[1],train loss is:0.485663 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         不标注       0.92      0.89      0.90      2109\n",
      "          其他       0.82      0.78      0.80       486\n",
      "          阳性       0.96      0.97      0.96      7192\n",
      "          阴性       0.91      0.94      0.93      1272\n",
      "\n",
      "    accuracy                           0.94     11059\n",
      "   macro avg       0.90      0.89      0.90     11059\n",
      "weighted avg       0.94      0.94      0.94     11059\n",
      "\n",
      "confusion_matrix_: \n",
      " [[1869   23  182   35]\n",
      " [  17  378   61   30]\n",
      " [ 132   42 6970   48]\n",
      " [  19   16   42 1195]]\n",
      "test loss is:0.454957,test acc is:0.941496,f1_score is:0.898214\n",
      "Some weights of the model checkpoint at trueto/medbert-base-chinese were not used when initializing Bert: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing Bert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Bert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Bert were not initialized from the model checkpoint at trueto/medbert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight', 'relative_pos_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  3%|█▏                                     | 99/3111 [03:41<1:52:29,  2.24s/it][99/3111],train loss is:1.023889\n",
      "  6%|██▍                                   | 199/3111 [07:26<1:48:46,  2.24s/it][199/3111],train loss is:0.898040\n",
      " 10%|███▋                                  | 299/3111 [11:10<1:43:58,  2.22s/it][299/3111],train loss is:0.829514\n",
      " 13%|████▊                                 | 399/3111 [14:52<1:40:44,  2.23s/it][399/3111],train loss is:0.785066\n",
      " 16%|██████                                | 499/3111 [18:35<1:37:11,  2.23s/it][499/3111],train loss is:0.751416\n",
      " 19%|███████▎                              | 599/3111 [22:19<1:33:28,  2.23s/it][599/3111],train loss is:0.729156\n",
      " 22%|████████▌                             | 699/3111 [26:02<1:29:43,  2.23s/it][699/3111],train loss is:0.710994\n",
      " 26%|█████████▊                            | 799/3111 [29:45<1:26:07,  2.24s/it][799/3111],train loss is:0.696888\n",
      " 29%|██████████▉                           | 899/3111 [33:28<1:22:30,  2.24s/it][899/3111],train loss is:0.683569\n",
      " 32%|████████████▏                         | 999/3111 [37:12<1:18:34,  2.23s/it][999/3111],train loss is:0.673614\n",
      " 35%|█████████████                        | 1099/3111 [40:55<1:14:39,  2.23s/it][1099/3111],train loss is:0.665101\n",
      " 39%|██████████████▎                      | 1199/3111 [44:38<1:11:04,  2.23s/it][1199/3111],train loss is:0.657854\n",
      " 42%|███████████████▍                     | 1299/3111 [48:21<1:07:32,  2.24s/it][1299/3111],train loss is:0.650805\n",
      " 45%|████████████████▋                    | 1399/3111 [52:04<1:03:38,  2.23s/it][1399/3111],train loss is:0.644701\n",
      " 48%|██████████████████▊                    | 1499/3111 [55:47<59:55,  2.23s/it][1499/3111],train loss is:0.638938\n",
      " 51%|████████████████████                   | 1599/3111 [59:31<56:15,  2.23s/it][1599/3111],train loss is:0.634700\n",
      " 55%|████████████████████▏                | 1699/3111 [1:03:14<52:30,  2.23s/it][1699/3111],train loss is:0.630087\n",
      " 58%|█████████████████████▍               | 1799/3111 [1:06:57<48:43,  2.23s/it][1799/3111],train loss is:0.626020\n",
      " 61%|██████████████████████▌              | 1899/3111 [1:10:40<45:07,  2.23s/it][1899/3111],train loss is:0.622557\n",
      " 64%|███████████████████████▊             | 1999/3111 [1:14:23<41:23,  2.23s/it][1999/3111],train loss is:0.619085\n",
      " 67%|████████████████████████▉            | 2099/3111 [1:18:07<37:38,  2.23s/it][2099/3111],train loss is:0.615670\n",
      " 71%|██████████████████████████▏          | 2199/3111 [1:21:50<33:52,  2.23s/it][2199/3111],train loss is:0.612806\n",
      " 74%|███████████████████████████▎         | 2299/3111 [1:25:33<30:08,  2.23s/it][2299/3111],train loss is:0.610123\n",
      " 77%|████████████████████████████▌        | 2399/3111 [1:29:16<26:25,  2.23s/it][2399/3111],train loss is:0.607296\n",
      " 80%|█████████████████████████████▋       | 2499/3111 [1:32:59<22:47,  2.24s/it][2499/3111],train loss is:0.604742\n",
      " 84%|██████████████████████████████▉      | 2599/3111 [1:36:42<19:08,  2.24s/it][2599/3111],train loss is:0.601803\n",
      " 87%|████████████████████████████████     | 2699/3111 [1:40:26<15:15,  2.22s/it][2699/3111],train loss is:0.599518\n",
      " 90%|█████████████████████████████████▎   | 2799/3111 [1:44:09<11:34,  2.23s/it][2799/3111],train loss is:0.597860\n",
      " 93%|██████████████████████████████████▍  | 2899/3111 [1:47:52<07:53,  2.23s/it][2899/3111],train loss is:0.596091\n",
      " 96%|███████████████████████████████████▋ | 2999/3111 [1:51:36<04:10,  2.23s/it][2999/3111],train loss is:0.594153\n",
      "100%|████████████████████████████████████▊| 3099/3111 [1:55:19<00:26,  2.24s/it][3099/3111],train loss is:0.592707\n",
      "100%|█████████████████████████████████████| 3111/3111 [1:55:44<00:00,  2.23s/it]\n",
      "epoch:[0],train loss is:0.592386 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         不标注       0.88      0.85      0.87      2105\n",
      "          其他       0.76      0.72      0.74       442\n",
      "          阳性       0.95      0.96      0.96      7173\n",
      "          阴性       0.91      0.92      0.92      1339\n",
      "\n",
      "    accuracy                           0.93     11059\n",
      "   macro avg       0.88      0.86      0.87     11059\n",
      "weighted avg       0.92      0.93      0.92     11059\n",
      "\n",
      "confusion_matrix_: \n",
      " [[1795   21  248   41]\n",
      " [  31  319   61   31]\n",
      " [ 188   51 6884   50]\n",
      " [  29   27   47 1236]]\n",
      "test loss is:0.483797,test acc is:0.925400,f1_score is:0.869790\n",
      "  3%|█▏                                     | 99/3111 [03:41<1:52:16,  2.24s/it][99/3111],train loss is:0.499675\n",
      "  6%|██▍                                   | 199/3111 [07:24<1:48:55,  2.24s/it][199/3111],train loss is:0.495575\n",
      " 10%|███▋                                  | 299/3111 [11:08<1:44:57,  2.24s/it][299/3111],train loss is:0.495155\n",
      " 13%|████▊                                 | 399/3111 [14:51<1:41:07,  2.24s/it][399/3111],train loss is:0.496202\n",
      " 16%|██████                                | 499/3111 [18:34<1:37:04,  2.23s/it][499/3111],train loss is:0.493099\n",
      " 19%|███████▎                              | 599/3111 [22:18<1:33:31,  2.23s/it][599/3111],train loss is:0.492590\n",
      " 22%|████████▌                             | 699/3111 [26:01<1:29:37,  2.23s/it][699/3111],train loss is:0.492302\n",
      " 26%|█████████▊                            | 799/3111 [29:44<1:26:10,  2.24s/it][799/3111],train loss is:0.492927\n",
      " 29%|██████████▉                           | 899/3111 [33:28<1:22:16,  2.23s/it][899/3111],train loss is:0.491736\n",
      " 32%|████████████▏                         | 999/3111 [37:11<1:18:31,  2.23s/it][999/3111],train loss is:0.492189\n",
      " 35%|█████████████                        | 1099/3111 [40:55<1:15:07,  2.24s/it][1099/3111],train loss is:0.492450\n",
      " 39%|██████████████▎                      | 1199/3111 [44:38<1:11:21,  2.24s/it][1199/3111],train loss is:0.492335\n",
      " 42%|███████████████▍                     | 1299/3111 [48:22<1:07:22,  2.23s/it][1299/3111],train loss is:0.492167\n",
      " 45%|████████████████▋                    | 1399/3111 [52:05<1:03:45,  2.23s/it][1399/3111],train loss is:0.491635\n",
      " 48%|█████████████████▊                   | 1499/3111 [55:49<1:00:17,  2.24s/it][1499/3111],train loss is:0.490996\n",
      " 51%|████████████████████                   | 1599/3111 [59:33<56:22,  2.24s/it][1599/3111],train loss is:0.491061\n",
      " 55%|████████████████████▏                | 1699/3111 [1:03:16<52:31,  2.23s/it][1699/3111],train loss is:0.490473\n",
      " 58%|█████████████████████▍               | 1799/3111 [1:07:00<48:50,  2.23s/it][1799/3111],train loss is:0.489114\n",
      " 61%|██████████████████████▌              | 1899/3111 [1:10:41<43:23,  2.15s/it][1899/3111],train loss is:0.489190\n",
      " 64%|███████████████████████▊             | 1999/3111 [1:14:16<39:35,  2.14s/it][1999/3111],train loss is:0.488505\n",
      " 67%|████████████████████████▉            | 2099/3111 [1:17:51<36:20,  2.15s/it][2099/3111],train loss is:0.487778\n",
      " 71%|██████████████████████████▏          | 2199/3111 [1:21:26<33:00,  2.17s/it][2199/3111],train loss is:0.487689\n",
      " 74%|███████████████████████████▎         | 2299/3111 [1:25:04<29:34,  2.19s/it][2299/3111],train loss is:0.487292\n",
      " 77%|████████████████████████████▌        | 2399/3111 [1:28:42<25:15,  2.13s/it][2399/3111],train loss is:0.486974\n",
      " 80%|█████████████████████████████▋       | 2499/3111 [1:32:15<21:45,  2.13s/it][2499/3111],train loss is:0.486199\n",
      " 84%|██████████████████████████████▉      | 2599/3111 [1:35:49<18:19,  2.15s/it][2599/3111],train loss is:0.486385\n",
      " 87%|████████████████████████████████     | 2699/3111 [1:39:30<15:32,  2.26s/it][2699/3111],train loss is:0.485911\n",
      " 90%|█████████████████████████████████▎   | 2799/3111 [1:43:12<10:51,  2.09s/it][2799/3111],train loss is:0.486005\n",
      " 93%|██████████████████████████████████▍  | 2899/3111 [1:46:41<07:23,  2.09s/it][2899/3111],train loss is:0.485594\n",
      " 96%|███████████████████████████████████▋ | 2999/3111 [1:50:11<03:55,  2.11s/it][2999/3111],train loss is:0.485321\n",
      "100%|████████████████████████████████████▊| 3099/3111 [1:53:43<00:25,  2.12s/it][3099/3111],train loss is:0.485358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3111/3111 [1:54:07<00:00,  2.20s/it]\n",
      "epoch:[1],train loss is:0.485351 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         不标注       0.90      0.88      0.89      2105\n",
      "          其他       0.82      0.77      0.80       442\n",
      "          阳性       0.96      0.97      0.96      7173\n",
      "          阴性       0.92      0.94      0.93      1339\n",
      "\n",
      "    accuracy                           0.94     11059\n",
      "   macro avg       0.90      0.89      0.89     11059\n",
      "weighted avg       0.94      0.94      0.94     11059\n",
      "\n",
      "confusion_matrix_: \n",
      " [[1859   18  192   36]\n",
      " [  30  340   49   23]\n",
      " [ 153   39 6927   54]\n",
      " [  25   16   45 1253]]\n",
      "test loss is:0.460727,test acc is:0.938512,f1_score is:0.893988\n",
      "Some weights of the model checkpoint at trueto/medbert-base-chinese were not used when initializing Bert: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing Bert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Bert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Bert were not initialized from the model checkpoint at trueto/medbert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight', 'relative_pos_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  3%|█▏                                     | 99/3111 [03:32<1:48:08,  2.15s/it][99/3111],train loss is:1.038081\n",
      "  6%|██▍                                   | 199/3111 [07:08<1:45:04,  2.16s/it][199/3111],train loss is:0.916957\n",
      " 10%|███▋                                  | 299/3111 [10:46<1:42:05,  2.18s/it][299/3111],train loss is:0.833672\n",
      " 13%|████▊                                 | 399/3111 [14:25<1:39:51,  2.21s/it][399/3111],train loss is:0.788557\n",
      " 16%|██████                                | 499/3111 [18:08<1:37:12,  2.23s/it][499/3111],train loss is:0.754246\n",
      " 19%|███████▎                              | 599/3111 [21:51<1:33:35,  2.24s/it][599/3111],train loss is:0.733109\n",
      " 22%|████████▌                             | 699/3111 [25:35<1:29:45,  2.23s/it][699/3111],train loss is:0.714243\n",
      " 26%|█████████▊                            | 799/3111 [29:19<1:25:58,  2.23s/it][799/3111],train loss is:0.699204\n",
      " 29%|██████████▉                           | 899/3111 [33:02<1:22:29,  2.24s/it][899/3111],train loss is:0.687015\n",
      " 32%|████████████▏                         | 999/3111 [36:46<1:18:42,  2.24s/it][999/3111],train loss is:0.677420\n",
      " 35%|█████████████                        | 1099/3111 [40:30<1:15:06,  2.24s/it][1099/3111],train loss is:0.669195\n",
      " 39%|██████████████▎                      | 1199/3111 [44:13<1:11:14,  2.24s/it][1199/3111],train loss is:0.661574\n",
      " 42%|███████████████▍                     | 1299/3111 [47:57<1:07:48,  2.25s/it][1299/3111],train loss is:0.653677\n",
      " 45%|████████████████▋                    | 1399/3111 [51:41<1:04:01,  2.24s/it][1399/3111],train loss is:0.646729\n",
      " 48%|█████████████████▊                   | 1499/3111 [55:25<1:00:11,  2.24s/it][1499/3111],train loss is:0.641584\n",
      " 51%|████████████████████                   | 1599/3111 [59:09<56:38,  2.25s/it][1599/3111],train loss is:0.635450\n",
      " 55%|████████████████████▏                | 1699/3111 [1:02:52<52:43,  2.24s/it][1699/3111],train loss is:0.630943\n",
      " 58%|█████████████████████▍               | 1799/3111 [1:06:36<48:59,  2.24s/it][1799/3111],train loss is:0.627056\n",
      " 61%|██████████████████████▌              | 1899/3111 [1:10:20<45:10,  2.24s/it][1899/3111],train loss is:0.623472\n",
      " 64%|███████████████████████▊             | 1999/3111 [1:14:05<41:23,  2.23s/it][1999/3111],train loss is:0.619274\n",
      " 67%|████████████████████████▉            | 2099/3111 [1:17:48<37:29,  2.22s/it][2099/3111],train loss is:0.616120\n",
      " 71%|██████████████████████████▏          | 2199/3111 [1:21:30<33:56,  2.23s/it][2199/3111],train loss is:0.614043\n",
      " 74%|███████████████████████████▎         | 2299/3111 [1:25:13<30:11,  2.23s/it][2299/3111],train loss is:0.610546\n",
      " 77%|████████████████████████████▌        | 2399/3111 [1:28:56<26:22,  2.22s/it][2399/3111],train loss is:0.607934\n",
      " 80%|█████████████████████████████▋       | 2499/3111 [1:32:39<22:50,  2.24s/it][2499/3111],train loss is:0.605201\n",
      " 84%|██████████████████████████████▉      | 2599/3111 [1:36:22<19:06,  2.24s/it][2599/3111],train loss is:0.602510\n",
      " 87%|████████████████████████████████     | 2699/3111 [1:40:06<15:21,  2.24s/it][2699/3111],train loss is:0.600245\n",
      " 90%|█████████████████████████████████▎   | 2799/3111 [1:43:50<11:39,  2.24s/it][2799/3111],train loss is:0.598225\n",
      " 93%|██████████████████████████████████▍  | 2899/3111 [1:47:35<07:54,  2.24s/it][2899/3111],train loss is:0.596435\n",
      " 96%|███████████████████████████████████▋ | 2999/3111 [1:51:20<04:11,  2.25s/it][2999/3111],train loss is:0.594281\n",
      "100%|████████████████████████████████████▊| 3099/3111 [1:55:05<00:26,  2.25s/it][3099/3111],train loss is:0.592150\n",
      "100%|█████████████████████████████████████| 3111/3111 [1:55:30<00:00,  2.23s/it]\n",
      "epoch:[0],train loss is:0.591861 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         不标注       0.89      0.85      0.87      2086\n",
      "          其他       0.79      0.73      0.76       445\n",
      "          阳性       0.95      0.97      0.96      7226\n",
      "          阴性       0.91      0.91      0.91      1302\n",
      "\n",
      "    accuracy                           0.93     11059\n",
      "   macro avg       0.89      0.87      0.88     11059\n",
      "weighted avg       0.93      0.93      0.93     11059\n",
      "\n",
      "confusion_matrix_: \n",
      " [[1775   17  257   37]\n",
      " [  15  327   68   35]\n",
      " [ 182   28 6974   42]\n",
      " [  20   43   48 1191]]\n",
      "test loss is:0.479090,test acc is:0.928384,f1_score is:0.875449\n",
      "  3%|█▏                                     | 99/3111 [03:41<1:51:06,  2.21s/it][99/3111],train loss is:0.488644\n",
      "  6%|██▍                                   | 199/3111 [07:22<1:46:42,  2.20s/it][199/3111],train loss is:0.488636\n",
      " 10%|███▋                                  | 299/3111 [11:02<1:43:14,  2.20s/it][299/3111],train loss is:0.488677\n",
      " 13%|████▊                                 | 399/3111 [14:42<1:39:23,  2.20s/it][399/3111],train loss is:0.488343\n",
      " 16%|██████                                | 499/3111 [18:23<1:35:52,  2.20s/it][499/3111],train loss is:0.490020\n",
      " 19%|███████▎                              | 599/3111 [22:04<1:32:09,  2.20s/it][599/3111],train loss is:0.488341\n",
      " 22%|████████▌                             | 699/3111 [25:39<1:26:25,  2.15s/it][699/3111],train loss is:0.489484\n",
      " 26%|█████████▊                            | 799/3111 [29:16<1:23:26,  2.17s/it][799/3111],train loss is:0.489949\n",
      " 29%|██████████▉                           | 899/3111 [32:53<1:20:21,  2.18s/it][899/3111],train loss is:0.489501\n",
      " 32%|████████████▏                         | 999/3111 [36:32<1:17:48,  2.21s/it][999/3111],train loss is:0.489806\n",
      " 35%|█████████████                        | 1099/3111 [40:14<1:14:36,  2.22s/it][1099/3111],train loss is:0.489909\n",
      " 39%|██████████████▎                      | 1199/3111 [43:56<1:10:40,  2.22s/it][1199/3111],train loss is:0.490540\n",
      " 42%|███████████████▍                     | 1299/3111 [47:38<1:07:07,  2.22s/it][1299/3111],train loss is:0.490003\n",
      " 45%|████████████████▋                    | 1399/3111 [51:20<1:03:13,  2.22s/it][1399/3111],train loss is:0.489073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████▊                    | 1499/3111 [55:02<59:36,  2.22s/it][1499/3111],train loss is:0.488228\n",
      " 51%|████████████████████                   | 1599/3111 [58:44<56:01,  2.22s/it][1599/3111],train loss is:0.488699\n",
      " 55%|████████████████████▏                | 1699/3111 [1:02:26<52:10,  2.22s/it][1699/3111],train loss is:0.487976\n",
      " 58%|█████████████████████▍               | 1799/3111 [1:06:08<48:29,  2.22s/it][1799/3111],train loss is:0.488082\n",
      " 61%|██████████████████████▌              | 1899/3111 [1:09:50<45:02,  2.23s/it][1899/3111],train loss is:0.487851\n",
      " 64%|███████████████████████▊             | 1999/3111 [1:13:32<41:02,  2.21s/it][1999/3111],train loss is:0.487255\n",
      " 67%|████████████████████████▉            | 2099/3111 [1:17:14<37:31,  2.22s/it][2099/3111],train loss is:0.487084\n",
      " 71%|██████████████████████████▏          | 2199/3111 [1:20:56<33:41,  2.22s/it][2199/3111],train loss is:0.487192\n",
      " 74%|███████████████████████████▎         | 2299/3111 [1:24:38<30:03,  2.22s/it][2299/3111],train loss is:0.487053\n",
      " 77%|████████████████████████████▌        | 2399/3111 [1:28:20<26:17,  2.22s/it][2399/3111],train loss is:0.486975\n",
      " 80%|█████████████████████████████▋       | 2499/3111 [1:32:02<22:43,  2.23s/it][2499/3111],train loss is:0.486402\n",
      " 84%|██████████████████████████████▉      | 2599/3111 [1:35:44<18:51,  2.21s/it][2599/3111],train loss is:0.486613\n",
      " 87%|████████████████████████████████     | 2699/3111 [1:39:26<15:15,  2.22s/it][2699/3111],train loss is:0.486554\n",
      " 90%|█████████████████████████████████▎   | 2799/3111 [1:43:09<11:32,  2.22s/it][2799/3111],train loss is:0.486391\n",
      " 93%|██████████████████████████████████▍  | 2899/3111 [1:46:51<07:49,  2.22s/it][2899/3111],train loss is:0.486510\n",
      " 96%|███████████████████████████████████▋ | 2999/3111 [1:50:33<04:08,  2.22s/it][2999/3111],train loss is:0.486196\n",
      "100%|████████████████████████████████████▊| 3099/3111 [1:54:15<00:26,  2.22s/it][3099/3111],train loss is:0.486115\n",
      "100%|█████████████████████████████████████| 3111/3111 [1:54:40<00:00,  2.21s/it]\n",
      "epoch:[1],train loss is:0.486099 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         不标注       0.92      0.88      0.90      2086\n",
      "          其他       0.82      0.77      0.79       445\n",
      "          阳性       0.96      0.97      0.96      7226\n",
      "          阴性       0.92      0.94      0.93      1302\n",
      "\n",
      "    accuracy                           0.94     11059\n",
      "   macro avg       0.90      0.89      0.90     11059\n",
      "weighted avg       0.94      0.94      0.94     11059\n",
      "\n",
      "confusion_matrix_: \n",
      " [[1830   15  209   32]\n",
      " [  13  344   56   32]\n",
      " [ 139   31 7011   45]\n",
      " [  14   31   38 1219]]\n",
      "test loss is:0.457193,test acc is:0.940772,f1_score is:0.895612\n",
      "Some weights of the model checkpoint at trueto/medbert-base-chinese were not used when initializing Bert: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing Bert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Bert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Bert were not initialized from the model checkpoint at trueto/medbert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight', 'relative_pos_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  3%|█▏                                     | 99/3111 [03:35<1:47:56,  2.15s/it][99/3111],train loss is:1.004195\n",
      "  6%|██▍                                   | 199/3111 [07:11<1:45:22,  2.17s/it][199/3111],train loss is:0.881564\n",
      " 10%|███▋                                  | 299/3111 [10:49<1:42:39,  2.19s/it][299/3111],train loss is:0.806248\n",
      " 13%|████▊                                 | 399/3111 [14:29<1:39:28,  2.20s/it][399/3111],train loss is:0.763873\n",
      " 16%|██████                                | 499/3111 [18:11<1:37:00,  2.23s/it][499/3111],train loss is:0.737696\n",
      " 19%|███████▎                              | 599/3111 [21:55<1:34:11,  2.25s/it][599/3111],train loss is:0.718081\n",
      " 22%|████████▌                             | 699/3111 [25:39<1:29:57,  2.24s/it][699/3111],train loss is:0.702363\n",
      " 26%|█████████▊                            | 799/3111 [29:23<1:26:06,  2.23s/it][799/3111],train loss is:0.689596\n",
      " 29%|██████████▉                           | 899/3111 [33:07<1:22:37,  2.24s/it][899/3111],train loss is:0.677602\n",
      " 32%|████████████▏                         | 999/3111 [36:52<1:18:57,  2.24s/it][999/3111],train loss is:0.667645\n",
      " 35%|█████████████                        | 1099/3111 [40:36<1:15:07,  2.24s/it][1099/3111],train loss is:0.660119\n",
      " 39%|██████████████▎                      | 1199/3111 [44:20<1:11:22,  2.24s/it][1199/3111],train loss is:0.653577\n",
      " 42%|███████████████▍                     | 1299/3111 [48:04<1:07:24,  2.23s/it][1299/3111],train loss is:0.648312\n",
      " 45%|████████████████▋                    | 1399/3111 [51:48<1:03:53,  2.24s/it][1399/3111],train loss is:0.642811\n",
      " 48%|█████████████████▊                   | 1499/3111 [55:32<1:00:08,  2.24s/it][1499/3111],train loss is:0.637503\n",
      " 51%|████████████████████                   | 1599/3111 [59:16<56:14,  2.23s/it][1599/3111],train loss is:0.632833\n",
      " 55%|████████████████████▏                | 1699/3111 [1:03:00<52:39,  2.24s/it][1699/3111],train loss is:0.628728\n",
      " 58%|█████████████████████▍               | 1799/3111 [1:06:44<48:56,  2.24s/it][1799/3111],train loss is:0.624856\n",
      " 61%|██████████████████████▌              | 1899/3111 [1:10:28<45:14,  2.24s/it][1899/3111],train loss is:0.620563\n",
      " 64%|███████████████████████▊             | 1999/3111 [1:14:12<41:33,  2.24s/it][1999/3111],train loss is:0.617257\n",
      " 67%|████████████████████████▉            | 2099/3111 [1:17:56<37:44,  2.24s/it][2099/3111],train loss is:0.613568\n",
      " 71%|██████████████████████████▏          | 2199/3111 [1:21:40<34:05,  2.24s/it][2199/3111],train loss is:0.610287\n",
      " 74%|███████████████████████████▎         | 2299/3111 [1:25:24<30:13,  2.23s/it][2299/3111],train loss is:0.607919\n",
      " 77%|████████████████████████████▌        | 2399/3111 [1:29:08<26:41,  2.25s/it][2399/3111],train loss is:0.605286\n",
      " 80%|█████████████████████████████▋       | 2499/3111 [1:32:53<22:49,  2.24s/it][2499/3111],train loss is:0.602185\n",
      " 84%|██████████████████████████████▉      | 2599/3111 [1:36:37<19:07,  2.24s/it][2599/3111],train loss is:0.600015\n",
      " 87%|████████████████████████████████     | 2699/3111 [1:40:21<15:22,  2.24s/it][2699/3111],train loss is:0.597440\n",
      " 90%|█████████████████████████████████▎   | 2799/3111 [1:44:05<11:38,  2.24s/it][2799/3111],train loss is:0.595119\n",
      " 93%|██████████████████████████████████▍  | 2899/3111 [1:47:49<07:54,  2.24s/it][2899/3111],train loss is:0.592889\n",
      " 96%|███████████████████████████████████▋ | 2999/3111 [1:51:32<04:11,  2.25s/it][2999/3111],train loss is:0.591235\n",
      "100%|████████████████████████████████████▊| 3099/3111 [1:55:17<00:26,  2.24s/it][3099/3111],train loss is:0.589396\n",
      "100%|█████████████████████████████████████| 3111/3111 [1:55:42<00:00,  2.23s/it]\n",
      "epoch:[0],train loss is:0.589234 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         不标注       0.88      0.86      0.87      2071\n",
      "          其他       0.76      0.68      0.72       470\n",
      "          阳性       0.95      0.96      0.95      7229\n",
      "          阴性       0.89      0.92      0.91      1289\n",
      "\n",
      "    accuracy                           0.92     11059\n",
      "   macro avg       0.87      0.85      0.86     11059\n",
      "weighted avg       0.92      0.92      0.92     11059\n",
      "\n",
      "confusion_matrix_: \n",
      " [[1777   16  242   36]\n",
      " [  26  319   75   50]\n",
      " [ 194   50 6928   57]\n",
      " [  17   37   44 1191]]\n",
      "test loss is:0.482989,test acc is:0.923682,f1_score is:0.861945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 67/3111 [02:30<1:53:44,  2.24s/it]"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 python ./medbert.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be44c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
